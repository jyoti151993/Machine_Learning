# -*- coding: utf-8 -*-
"""MedicalInsur_Stacking_Reg_Anova.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Z8EVFiwEmeIxf8m4BdFo5NGZwxsITIX
"""

!pip install xgboost

import pandas as pd
from sklearn.model_selection import KFold,cross_val_score, GridSearchCV , cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import r2_score
from sklearn.naive_bayes import GaussianNB
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import GradientBoostingClassifier,StackingRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor 
from sklearn.linear_model import ElasticNet, LinearRegression
import os
from xgboost import XGBRegressor
import numpy as np

ins=pd.read_csv("/content/insurance.csv")
dum_ins=pd.get_dummies(ins,drop_first=True)
x=dum_ins.drop("charges",axis=1)
y=dum_ins["charges"]

lr=LinearRegression()

from xgboost.sklearn import XGBRegressor
elastic=ElasticNet(random_state=2023)
dtr=DecisionTreeRegressor(random_state=True)
xgbm=XGBRegressor(random_state=2023)              

kfold=KFold(random_state=2023,shuffle=True)
stack=StackingRegressor(estimators=[('LR',lr),('ELASTIC',elastic),('DTR',dtr)],final_estimator=xgbm,passthrough=True,cv=kfold)

stack.get_params()

import numpy as np 
params={'final_estimator__learning_rate':np.linspace(0.01,0.5,5), 'final_estimator__n_estimators':[20,50], 'final_estimator__max_depth':[3,5],'ELASTIC__alpha':np.linspace(0.001,10,5), 'ELASTIC__l1_ratio':np.linspace(0,1,5),'DTR__max_depth':[None,2,4],'DTR__min_samples_split':[2,5,10],'DTR__min_samples_leaf':[1,4]}
gcv=GridSearchCV(stack, param_grid=params, cv=kfold, scoring='r2',verbose=3, n_jobs=-1)

gcv.fit(x,y)

gcv.best_score_

gcv.best_params_

"""##Kaggle Bike Share Demand : light GBM"""

!pip install lightgbm

from lightgbm import LGBMClassifier
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor

train=pd.read_csv("/var/train.csv")
train.head()

test=pd.read_csv("/var/test.csv")
test.head()

train['season']=train['season'].astype(object)
test['season']=test['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['count']
X_test=test.drop('datetime',axis=1)

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

X_train.shape

X_test.shape

X_train.columns

X_test.columns

y_train.shape

rf=RandomForestRegressor(random_state=2023)

kfold = KFold(n_splits=5, shuffle=True, random_state=2023)
params={'max_features':[3,4,5,6,7]}
gcv=GridSearchCV(rf, param_grid=params, cv=kfold, scoring='r2', n_jobs=-1)
gcv.fit(X_train,y_train)
print(gcv.best_params_)  # max_features =3
print(gcv.best_score_)  # .32

best_model=gcv.best_estimator_
y_pred=best_model.predict(X_test)
y_pred[y_pred<0]=0

s_submission=pd.read_csv("/var/sampleSubmission.csv")

os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("rf_pred.csv",index=False)

"""## Including Date Time"""

train=pd.read_csv("/var/train.csv",parse_dates=['datetime'])
train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

test=pd.read_csv("/var/test.csv",parse_dates=['datetime'])
test['year']=test['datetime'].dt.year
test['month']=test['datetime'].dt.month
test['day']=test['datetime'].dt.day
test['hour']=test['datetime'].dt.hour
test['weekday']=test['datetime'].dt.weekday
test['season']=test['season'].astype(object)

train['season']=train['season'].astype(object)
test['season']=test['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['count']
X_test=test.drop('datetime',axis=1)

X_train.columns

X_test.columns

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

rf=RandomForestRegressor(random_state=2023)
kfold = KFold(n_splits=5, shuffle=True, random_state=2023)
params={'max_features':[3,4,5,6,7]}
gcv=GridSearchCV(rf, param_grid=params, cv=kfold, scoring='r2', n_jobs=-1)
gcv.fit(X_train,y_train)
print(gcv.best_params_)  # max_features =3
print(gcv.best_score_)

best_model=gcv.best_estimator_
y_pred=best_model.predict(X_test)
y_pred[y_pred<0]=0

s_submission=pd.read_csv("/var/sampleSubmission.csv")

s_submission=pd.read_csv("/var/sampleSubmission.csv")
os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("rf_pred_with_datetime.csv",index=False)

"""##### **ANOVA**"""

from statsmodels.stats.anova import anova_lm
from statsmodels.formula.api import ols
train.columns

aov_model=ols('count~weekday',data=train).fit()
table=anova_lm(aov_model,typ=2)
print(table)

aov_model=ols('count~casual',data=train).fit()
table=anova_lm(aov_model,typ=2)
print(table)

aov_model=ols('count~registered',data=train).fit()
table=anova_lm(aov_model,typ=2)
print(table)

aov_model=ols('casual~weekday',data=train).fit()
table=anova_lm(aov_model,typ=2)
print(table)

aov_model=ols('registered~weekday',data=train).fit()
table=anova_lm(aov_model,typ=2)
print(table)

import matplotlib.pyplot as plt
import seaborn as sns

train.head()

cas_grp=train.groupby("weekday")['casual'].mean()
cas_grp

plt.bar([0,1,2,3,4,5,6], cas_grp, color='g')
plt.title("Weekday vs mean of casuals")
plt.show()

reg_grp=train.groupby("weekday")['registered'].mean()
reg_grp

plt.bar([0,1,2,3,4,5,6], reg_grp,color="r")
plt.title("Weekday vs mean of registered",color='R')
plt.show()



"""#### **Data centric**"""

train=pd.read_csv("/var/train.csv",parse_dates=['datetime'])
train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

test=pd.read_csv("/var/test.csv",parse_dates=['datetime'])
test['year']=test['datetime'].dt.year
test['month']=test['datetime'].dt.month
test['day']=test['datetime'].dt.day
test['hour']=test['datetime'].dt.hour
test['weekday']=test['datetime'].dt.weekday
test['season']=test['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['casual']
X_test=test.drop('datetime',axis=1)

X_train.columns

X_test.columns

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

rf1=RandomForestRegressor(random_state=2023)
rf1.fit(X_train,y_train)

y_pred1=rf1.predict(X_test)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['registered']
X_test=test.drop('datetime',axis=1)

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

rf2=RandomForestRegressor(random_state=2023)
rf2.fit(X_train,y_train)

y_pred2=rf2.predict(X_test)

y_pred=y_pred1+y_pred2

s_submission=pd.read_csv("/var/sampleSubmission.csv")

os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("rf_pred_with_rf1_rf2.csv",index=False)

#### LGM 
!pip install lightgbm

from lightgbm import LGBMRegressor

lgbm=LGBMRegressor(random_state=2023)

train=pd.read_csv("/var/train.csv",parse_dates=['datetime'])
train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

test=pd.read_csv("/var/test.csv",parse_dates=['datetime'])
test['year']=test['datetime'].dt.year
test['month']=test['datetime'].dt.month
test['day']=test['datetime'].dt.day
test['hour']=test['datetime'].dt.hour
test['weekday']=test['datetime'].dt.weekday
test['season']=test['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['count']
X_test=test.drop('datetime',axis=1)

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

lgbm=LGBMRegressor(random_state=2023)
lgbm.fit(X_train,y_train)

y_pred=lgbm.predict(X_test)

y_pred[y_pred<0]=0

s_submission=pd.read_csv("/var/sampleSubmission.csv")

os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("lgbm1.csv",index=False)

"""***XGBOOST***"""

!pip install xgboost

from xgboost import XGBRegressor

train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

test=pd.read_csv("/var/test.csv",parse_dates=['datetime'])
test['year']=test['datetime'].dt.year
test['month']=test['datetime'].dt.month
test['day']=test['datetime'].dt.day
test['hour']=test['datetime'].dt.hour
test['weekday']=test['datetime'].dt.weekday
test['season']=test['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['count']
X_test=test.drop('datetime',axis=1)

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

xgbm=XGBRegressor()
xgbm.fit(X_train,y_train)

y_pred=xgbm.predict(X_test)

y_pred[y_pred<0]=0

s_submission=pd.read_csv("/var/sampleSubmission.csv")

os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("xgbm.csv",index=False)

"""***CAT_Booster Regressor***"""

!pip install catboost

from catboost import CatBoostRegressor

train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

train['year']=train['datetime'].dt.year
train['month']=train['datetime'].dt.month
train['day']=train['datetime'].dt.day
train['hour']=train['datetime'].dt.hour
train['weekday']=train['datetime'].dt.weekday
train['season']=train['season'].astype(object)

X_train=train.drop(['datetime','casual','registered','count'],axis=1)
y_train=train['count']
X_test=test.drop('datetime',axis=1)

X_train=pd.get_dummies(X_train)
X_test=pd.get_dummies(X_test)

cat=CatBoostRegressor(random_state=2023)
cat.fit(X_train,y_train)

y_pred=cat.predict(X_test)

y_pred[y_pred<0]=0

s_submission=pd.read_csv("/var/sampleSubmission.csv")

os.chdir(r"/var")
s_submission['count']=y_pred
s_submission.to_csv("catR.csv",index=False)

